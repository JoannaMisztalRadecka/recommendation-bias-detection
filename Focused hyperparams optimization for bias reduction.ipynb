{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "import hashlib\n",
    "\n",
    "from bias_tree import BiasDetectionTree, get_metric_bias_tree_for_model, evaluate_model\n",
    "from data_preparation.movielens_100k import MovieLens100KData\n",
    "from recommender.factorization_recommender import fit_recommendation_model, retrain_recommendation_model,\\\n",
    "tune_recommendation_hyperparams, BiasEvaluationCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MovieLens100KData(data_path='data/ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze minimum and maximum biased nodes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 1000\n",
    "MAX_TRIAL = 50\n",
    "BIAS_EVAL_INTERVAL = 2\n",
    "EMBEDDING_SIZE = 128\n",
    "MIN_CHILD_NODE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias_results_runs = []\n",
    "\n",
    "\n",
    "X_train, X_val, X_test = data.get_data_splits_for_training()\n",
    "bias_callback = BiasEvaluationCallback(X_train, X_val, data, interval=BIAS_EVAL_INTERVAL, min_child_node_size=MIN_CHILD_NODE_SIZE)\n",
    "model, history =  fit_recommendation_model(X_train, X_val, user_ids=data.user_ids, item_ids=data.item_ids, \n",
    "                                             batch_size=BATCH_SIZE, epochs=NUM_EPOCH, callbacks=[bias_callback], \n",
    "                                           embedding_size=EMBEDDING_SIZE)\n",
    "bias_results_runs += bias_callback.bias_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_results_epochs = pd.DataFrame(bias_results_runs)\n",
    "\n",
    "bias_results_epochs = bias_results_epochs[bias_results_epochs['epoch']>0]\n",
    "\n",
    "bias_results_epochs.replace('train-min node', 'train: min node value', inplace=True)\n",
    "bias_results_epochs.replace('train-max node', 'train: max node value', inplace=True)\n",
    "bias_results_epochs.replace('val-min node', 'validation: min node value', inplace=True)\n",
    "bias_results_epochs.replace('val-max node', 'validation: max node value', inplace=True)\n",
    "bias_results_epochs.replace('avg-train', 'train: average value', inplace=True)\n",
    "bias_results_epochs.replace('avg-val', 'validation: average value', inplace=True)\n",
    "bias_results_epochs.rename(columns={'value': 'MSE'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.lineplot(data=bias_results_epochs, x='epoch', y='MSE', hue='metric')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_results_epochs.to_excel('bias_node_results_dnn_10runs.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CHILD_NODE_SIZE = 1000\n",
    "METRIC = 'squared_error'\n",
    "NUM_EPOCH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning for the global validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%Y%m%d %H%M%S\")\n",
    "model =  tune_recommendation_hyperparams(X_train, X_val, user_ids=data.user_ids, item_ids=data.item_ids, \n",
    "                                             batch_size=BATCH_SIZE, epochs=NUM_EPOCH, project_suffix=now, max_trials=MAX_TRIAL, \n",
    "                                         logdir='hyperparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tree_test = get_metric_bias_tree_for_model(model, X_val, data.attributes_dict, \n",
    "                                                 metric_name=METRIC,\n",
    "                                                min_child_node_size=MIN_CHILD_NODE_SIZE)\n",
    "display(bias_tree_test.leaf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximum and minimum biased nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_tree_test.max_metric_node, round(bias_tree_test.max_metric_value, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_tree_test.max_metric_node, round(bias_tree_test.min_metric_value, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for the biased nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_BIAS = 256\n",
    "mean_test_metric = evaluate_model(model, X_test, METRIC).mean() \n",
    "retrain_metrics = []\n",
    "biased_nodes = bias_tree_test.leaf_metrics[bias_tree_test.leaf_metrics['mean'] > mean_test_metric]\n",
    "for i, node_rules in biased_nodes.iterrows():\n",
    "    print(node_rules.name,  node_rules[\"mean\"])\n",
    "    X_train_filtered = bias_tree_test.get_filtered_df(node_rules.name,  X_train)\n",
    "    X_val_filtered = BiasDetectionTree.get_filtered_df(node_rules.name,  X_val)\n",
    "    X_test_filtered = BiasDetectionTree.get_filtered_df(node_rules.name,  X_test)\n",
    "    model_tuned_bias = tune_recommendation_hyperparams(X_train, X_val_filtered, user_ids=data.user_ids, item_ids=data.item_ids, \n",
    "                                 epochs=NUM_EPOCH, project_suffix=hashlib.md5(node_rules.name.encode()).hexdigest()[:5] + now,\n",
    "                                                      batch_size=BATCH_SIZE_BIAS, max_trials=50)\n",
    "#     model_bias = retrain_recommendation_model(X_train, X_val_filtered, model=model, epochs=10, \n",
    "#                                               retrain_embeddings=False)    \n",
    "    node_test_metric_after_retraining = evaluate_model(model_tuned_bias, X_test_filtered, METRIC).mean()\n",
    "    node_val_metric_after_retraining = evaluate_model(model_tuned_bias,  X_val_filtered, METRIC).mean()\n",
    "    node_test_metric_before_retraining = evaluate_model(model,  X_test_filtered, METRIC).mean()\n",
    "    node_val_metric_before_retraining = evaluate_model(model, X_val_filtered, METRIC).mean()\n",
    "    retrain_metrics.append({\n",
    "        'node_rules': node_rules.name,\n",
    "        'node_test_metric_before_retraining':  node_test_metric_before_retraining,\n",
    "        'node_val_metric_before_retraining':  node_val_metric_before_retraining,\n",
    "        'node_test_metric_after_retraining': node_test_metric_after_retraining,\n",
    "        'node_val_metric_after_retraining': node_val_metric_after_retraining\n",
    "    })\n",
    "retrain_metrics_pd = pd.DataFrame(retrain_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_metrics_pd['retrain_test_diff'] = 100*(retrain_metrics_pd['node_test_metric_before_retraining'] \\\n",
    "                                          - retrain_metrics_pd['node_test_metric_after_retraining'])\\\n",
    "                              /retrain_metrics_pd['node_test_metric_before_retraining']\n",
    "\n",
    "retrain_metrics_pd['retrain_val_diff'] = 100*(retrain_metrics_pd['node_val_metric_before_retraining'] \\\n",
    "                                          - retrain_metrics_pd['node_val_metric_after_retraining'])\\\n",
    "                                          /retrain_metrics_pd['node_val_metric_before_retraining']\n",
    "retrain_metrics_pd.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
